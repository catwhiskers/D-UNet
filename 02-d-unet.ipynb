{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing under Conda \n",
    "\n",
    "* install necessary pacakges under conda env tensorflow_p36 \n",
    "* to save time, use validation dataset as training set \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "pip install nibabel opencv-python matplotlib keras==2.3.1 \n",
    "mkdir -p h5 \n",
    "mkdir -p h5/detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to previous 5 sites to reduce execution time \n",
    "!python data_load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Stroke_segment.py local train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build D-Unet container \n",
    "\n",
    "* Dockerfile - install necessary packages and setup entrypoints \n",
    "* build_and_push - communicate with ECR (ElasticContainerRegistry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd container \n",
    "./build_and_push.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "client = boto3.client(\"sts\")\n",
    "account_id = client.get_caller_identity()[\"Account\"]\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/dunet\".format(account_id, \"us-west-2\")\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training locally based on the docker image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "mkdir -p input\n",
    "mkdir -p input/data\n",
    "mkdir -p input/data/atlas\n",
    "mv h5 input/data/atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-docker run -it -v $PWD:/opt/ml 938149709838.dkr.ecr.us-west-2.amazonaws.com/dunet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SageMaker Training Jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"dunet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload data to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./input/data/ && aws s3 cp --recursive atlas s3://{bucket}/{prefix}/atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define s3 input and output paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_h5_data = \"s3://{}/{}/atlas/\".format(bucket, prefix)\n",
    "outpath = \"s3://{}/{}/output/\".format(bucket, prefix)\n",
    "repositoryUri = image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define job_name and  and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "job_name = \"dunet-{}\".format(str(int(timestamp))) \n",
    "job_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit training job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_input = sagemaker.inputs.TrainingInput(atlas_h5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator( \n",
    "                        role=role,\n",
    "                        image_uri=repositoryUri,\n",
    "                        instance_count=1,\n",
    "                        instance_type='ml.p3.8xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        volume_size=100, \n",
    "                        debugger_hook_config=False\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\u001b[0m\n",
      "\u001b[34mEpoch 1/150\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs={\"atlas\":atlas_input}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "“alphapose.ipynb”",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
