{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing under Conda \n",
    "\n",
    "* install necessary pacakges under conda env tensorflow_p36 \n",
    "* to save time, use validation dataset as training set \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "pip install nibabel opencv-python matplotlib keras==2.3.1 \n",
    "mkdir -p h5 \n",
    "mkdir -p h5/detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to previous 5 sites to reduce execution time \n",
    "!python data_load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Stroke_segment.py local train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build D-Unet container \n",
    "\n",
    "* Dockerfile - install necessary packages and setup entrypoints \n",
    "* build_and_push - communicate with ECR (ElasticContainerRegistry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd container \n",
    "./build_and_push.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "client = boto3.client(\"sts\")\n",
    "account_id = client.get_caller_identity()[\"Account\"]\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/dunet\".format(account_id, \"us-west-2\")\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training locally based on the docker image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "mkdir -p input\n",
    "mkdir -p input/data\n",
    "mkdir -p input/data/atlas\n",
    "mv h5 input/data/atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-docker run -it -v $PWD:/opt/ml 230755935769.dkr.ecr.us-west-2.amazonaws.com/dunet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SageMaker Training Jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"dunet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload data to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./input/data/ && aws s3 cp --recursive atlas s3://{bucket}/{prefix}/atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define s3 input and output paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_h5_data = \"s3://{}/{}/atlas/\".format(bucket, prefix)\n",
    "outpath = \"s3://{}/{}/output/\".format(bucket, prefix)\n",
    "repositoryUri = image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define job_name and  and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "job_name = \"dunet-{}\".format(str(int(timestamp))) \n",
    "job_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit training job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_input = sagemaker.inputs.TrainingInput(atlas_h5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator( \n",
    "                        role=role,\n",
    "                        image_uri=repositoryUri,\n",
    "                        instance_count=1,\n",
    "                        instance_type='ml.p3.8xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        volume_size=100, \n",
    "                        debugger_hook_config=False\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      "2021-05-03 12:39:21 Training - Downloading the training image...............\n",
      "2021-05-03 12:41:44 Training - Training image download completed. Training in progress.\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m['Stroke_segment.py', 'sagemaker', 'train', 'train']\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:45.993748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.415892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.417247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1b.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.417349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.418584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 1 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1c.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.418673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.419906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 2 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1d.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.419991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.421243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 3 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.424030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.484754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.513164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.522185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.602487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.645132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.772317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.772453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.773863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.775145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.776411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.777716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.778997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.780313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.781635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.782858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0, 1, 2, 3\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.784168: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.801982: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300020000 Hz\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.804626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56483b44c480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:46.804663: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.674707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.678801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.685140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.693603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.695209: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56483b3d3730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.695241: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.695251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.695258: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.695264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.699960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.701230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1b.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.701320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.702535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 1 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1c.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.702613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.703823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 2 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1d.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.703900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 3 with properties: \u001b[0m\n",
      "\u001b[34mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[34mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.705419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.706677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.707930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.709203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.710453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.711702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.712972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.714223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.715428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0, 1, 2, 3\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.716142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.722238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.722274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 1 2 3 \u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.722284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N Y Y Y \u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.722291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   Y N Y Y \u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.722298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   Y Y N Y \u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.722304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   Y Y Y N \u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.723009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.724296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.725611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.726890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.728176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.729469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15059 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.730124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.732321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15059 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.733161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.734406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 15059 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.734986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2021-05-03 12:41:47.736233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15059 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/D-UNet/model.py:185: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input=inputs, output=conv10)\u001b[0m\n",
      "\u001b[34mModel: \"model_1\"\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                    Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34minput_1 (InputLayer)            (None, 192, 192, 4)  0                                            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mlambda_1 (Lambda)               (None, 192, 192, 4,  0           input_1[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_1 (Conv3D)               (None, 192, 192, 4,  896         lambda_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_1 (BatchNor (None, 192, 192, 4,  128         conv3d_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_1 (Activation)       (None, 192, 192, 4,  0           batch_normalization_1[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_1 (Conv2D)               (None, 192, 192, 32) 1184        input_1[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_2 (Conv3D)               (None, 192, 192, 4,  27680       activation_1[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_7 (BatchNor (None, 192, 192, 32) 128         conv2d_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_2 (BatchNor (None, 192, 192, 4,  128         conv3d_2[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_7 (Activation)       (None, 192, 192, 32) 0           batch_normalization_7[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_2 (Activation)       (None, 192, 192, 4,  0           batch_normalization_2[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_2 (Conv2D)               (None, 192, 192, 32) 9248        activation_7[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling3d_1 (MaxPooling3D)  (None, 96, 96, 2, 32 0           activation_2[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_8 (BatchNor (None, 192, 192, 32) 128         conv2d_2[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_3 (Conv3D)               (None, 96, 96, 2, 64 55360       max_pooling3d_1[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_8 (Activation)       (None, 192, 192, 32) 0           batch_normalization_8[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_3 (BatchNor (None, 96, 96, 2, 64 256         conv3d_3[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_3 (Activation)       (None, 96, 96, 2, 64 0           batch_normalization_3[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_1 (MaxPooling2D)  (None, 96, 96, 32)   0           activation_8[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_4 (Conv3D)               (None, 96, 96, 2, 64 110656      activation_3[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_3 (Conv2D)               (None, 96, 96, 64)   18496       max_pooling2d_1[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_4 (BatchNor (None, 96, 96, 2, 64 256         conv3d_4[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_9 (BatchNor (None, 96, 96, 64)   256         conv2d_3[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_4 (Activation)       (None, 96, 96, 2, 64 0           batch_normalization_4[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_9 (Activation)       (None, 96, 96, 64)   0           batch_normalization_9[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_7 (Conv3D)               (None, 96, 96, 2, 1) 65          activation_4[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_4 (Conv2D)               (None, 96, 96, 64)   36928       activation_9[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mlambda_2 (Lambda)               (None, 96, 96, 2)    0           conv3d_7[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_10 (BatchNo (None, 96, 96, 64)   256         conv2d_4[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_5 (Conv2D)               (None, 96, 96, 64)   1216        lambda_2[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_10 (Activation)      (None, 96, 96, 64)   0           batch_normalization_10[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mglobal_average_pooling2d_1 (Glo (None, 64)           0           conv2d_5[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mglobal_average_pooling2d_2 (Glo (None, 64)           0           activation_10[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape_1 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_1[0][0] \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape_2 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)                 (None, 1, 1, 4)      256         reshape_1[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_3 (Dense)                 (None, 1, 1, 4)      256         reshape_2[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_2 (Dense)                 (None, 1, 1, 64)     256         dense_1[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_4 (Dense)                 (None, 1, 1, 64)     256         dense_3[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling3d_2 (MaxPooling3D)  (None, 48, 48, 1, 64 0           activation_4[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmultiply_1 (Multiply)           (None, 96, 96, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 dense_2[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmultiply_2 (Multiply)           (None, 96, 96, 64)   0           activation_10[0][0]              \n",
      "                                                                 dense_4[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_5 (Conv3D)               (None, 48, 48, 1, 12 221312      max_pooling3d_2[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34madd_1 (Add)                     (None, 96, 96, 64)   0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_5 (BatchNor (None, 48, 48, 1, 12 512         conv3d_5[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_5 (Activation)       (None, 48, 48, 1, 12 0           batch_normalization_5[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 64)   0           add_1[0][0]                      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_6 (Conv3D)               (None, 48, 48, 1, 12 442496      activation_5[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_6 (Conv2D)               (None, 48, 48, 128)  73856       max_pooling2d_2[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_6 (BatchNor (None, 48, 48, 1, 12 512         conv3d_6[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_11 (BatchNo (None, 48, 48, 128)  512         conv2d_6[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_6 (Activation)       (None, 48, 48, 1, 12 0           batch_normalization_6[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_11 (Activation)      (None, 48, 48, 128)  0           batch_normalization_11[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv3d_8 (Conv3D)               (None, 48, 48, 1, 1) 129         activation_6[0][0]               \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_7 (Conv2D)               (None, 48, 48, 128)  147584      activation_11[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mlambda_3 (Lambda)               (None, 48, 48, 1)    0           conv3d_8[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_12 (BatchNo (None, 48, 48, 128)  512         conv2d_7[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_8 (Conv2D)               (None, 48, 48, 128)  1280        lambda_3[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_12 (Activation)      (None, 48, 48, 128)  0           batch_normalization_12[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mglobal_average_pooling2d_3 (Glo (None, 128)          0           conv2d_8[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mglobal_average_pooling2d_4 (Glo (None, 128)          0           activation_12[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape_3 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_3[0][0] \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape_4 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_4[0][0] \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_5 (Dense)                 (None, 1, 1, 8)      1024        reshape_3[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_7 (Dense)                 (None, 1, 1, 8)      1024        reshape_4[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_6 (Dense)                 (None, 1, 1, 128)    1024        dense_5[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_8 (Dense)                 (None, 1, 1, 128)    1024        dense_7[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmultiply_3 (Multiply)           (None, 48, 48, 128)  0           conv2d_8[0][0]                   \n",
      "                                                                 dense_6[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmultiply_4 (Multiply)           (None, 48, 48, 128)  0           activation_12[0][0]              \n",
      "                                                                 dense_8[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34madd_2 (Add)                     (None, 48, 48, 128)  0           multiply_3[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_3 (MaxPooling2D)  (None, 24, 24, 128)  0           add_2[0][0]                      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_9 (Conv2D)               (None, 24, 24, 256)  295168      max_pooling2d_3[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_13 (BatchNo (None, 24, 24, 256)  1024        conv2d_9[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_13 (Activation)      (None, 24, 24, 256)  0           batch_normalization_13[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_10 (Conv2D)              (None, 24, 24, 256)  590080      activation_13[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_14 (BatchNo (None, 24, 24, 256)  1024        conv2d_10[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_14 (Activation)      (None, 24, 24, 256)  0           batch_normalization_14[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_1 (Dropout)             (None, 24, 24, 256)  0           activation_14[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 256)  0           dropout_1[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_11 (Conv2D)              (None, 12, 12, 512)  1180160     max_pooling2d_4[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_15 (BatchNo (None, 12, 12, 512)  2048        conv2d_11[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_15 (Activation)      (None, 12, 12, 512)  0           batch_normalization_15[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_12 (Conv2D)              (None, 12, 12, 512)  2359808     activation_15[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_16 (BatchNo (None, 12, 12, 512)  2048        conv2d_12[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_16 (Activation)      (None, 12, 12, 512)  0           batch_normalization_16[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_2 (Dropout)             (None, 12, 12, 512)  0           activation_16[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mup_sampling2d_1 (UpSampling2D)  (None, 24, 24, 512)  0           dropout_2[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_13 (Conv2D)              (None, 24, 24, 256)  524544      up_sampling2d_1[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate_1 (Concatenate)     (None, 24, 24, 512)  0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_14 (Conv2D)              (None, 24, 24, 256)  1179904     concatenate_1[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_17 (BatchNo (None, 24, 24, 256)  1024        conv2d_14[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_17 (Activation)      (None, 24, 24, 256)  0           batch_normalization_17[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_15 (Conv2D)              (None, 24, 24, 256)  590080      activation_17[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_18 (BatchNo (None, 24, 24, 256)  1024        conv2d_15[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_18 (Activation)      (None, 24, 24, 256)  0           batch_normalization_18[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mup_sampling2d_2 (UpSampling2D)  (None, 48, 48, 256)  0           activation_18[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_16 (Conv2D)              (None, 48, 48, 128)  131200      up_sampling2d_2[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate_2 (Concatenate)     (None, 48, 48, 256)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_16[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_17 (Conv2D)              (None, 48, 48, 128)  295040      concatenate_2[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_19 (BatchNo (None, 48, 48, 128)  512         conv2d_17[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_19 (Activation)      (None, 48, 48, 128)  0           batch_normalization_19[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_18 (Conv2D)              (None, 48, 48, 128)  147584      activation_19[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_20 (BatchNo (None, 48, 48, 128)  512         conv2d_18[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_20 (Activation)      (None, 48, 48, 128)  0           batch_normalization_20[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mup_sampling2d_3 (UpSampling2D)  (None, 96, 96, 128)  0           activation_20[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_19 (Conv2D)              (None, 96, 96, 64)   32832       up_sampling2d_3[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate_3 (Concatenate)     (None, 96, 96, 128)  0           add_1[0][0]                      \n",
      "                                                                 conv2d_19[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_20 (Conv2D)              (None, 96, 96, 64)   73792       concatenate_3[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_21 (BatchNo (None, 96, 96, 64)   256         conv2d_20[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_21 (Activation)      (None, 96, 96, 64)   0           batch_normalization_21[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_21 (Conv2D)              (None, 96, 96, 64)   36928       activation_21[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_22 (BatchNo (None, 96, 96, 64)   256         conv2d_21[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_22 (Activation)      (None, 96, 96, 64)   0           batch_normalization_22[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mup_sampling2d_4 (UpSampling2D)  (None, 192, 192, 64) 0           activation_22[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_22 (Conv2D)              (None, 192, 192, 32) 8224        up_sampling2d_4[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate_4 (Concatenate)     (None, 192, 192, 64) 0           activation_8[0][0]               \n",
      "                                                                 conv2d_22[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_23 (Conv2D)              (None, 192, 192, 32) 18464       concatenate_4[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_23 (BatchNo (None, 192, 192, 32) 128         conv2d_23[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_23 (Activation)      (None, 192, 192, 32) 0           batch_normalization_23[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_24 (Conv2D)              (None, 192, 192, 32) 9248        activation_23[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_24 (BatchNo (None, 192, 192, 32) 128         conv2d_24[0][0]                  \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation_24 (Activation)      (None, 192, 192, 32) 0           batch_normalization_24[0][0]     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_25 (Conv2D)              (None, 192, 192, 1)  33          activation_24[0][0]              \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 8,640,163\u001b[0m\n",
      "\u001b[34mTrainable params: 8,633,379\u001b[0m\n",
      "\u001b[34mNon-trainable params: 6,784\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /D-UNet/Statistics.py:104: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mno loading weight!\u001b[0m\n",
      "\u001b[34mStroke_segment.py:58: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  h5 = h5py.File('{}/h5/train'.format(config['data_root']))\u001b[0m\n",
      "\u001b[34m['data_val', 'label_val']\u001b[0m\n",
      "\u001b[34mStroke_segment.py:63: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  h5 = h5py.File('{}/h5/test_0.8'.format(config['data_root']))\u001b[0m\n",
      "\u001b[34m<HDF5 file \"test_0.8\" (mode r+)>\u001b[0m\n",
      "\u001b[34m['data', 'label']\u001b[0m\n",
      "\u001b[34mtraining data:8694  validation data:8694\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\u001b[0m\n",
      "\u001b[34mEpoch 1/150\u001b[0m\n",
      "\u001b[34m2021-05-03 12:44:05.394927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\u001b[0m\n",
      "\u001b[34m2021-05-03 12:44:08.438524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\u001b[0m\n",
      "\u001b[34m - 153s - loss: 4.6615 - dice_coef: 0.0147 - val_loss: 4.2354 - val_dice_coef: 0.0139\u001b[0m\n",
      "\u001b[34mEpoch 2/150\u001b[0m\n",
      "\u001b[34m - 123s - loss: 4.6225 - dice_coef: 0.0150 - val_loss: 3.7540 - val_dice_coef: 0.0168\u001b[0m\n",
      "\u001b[34mEpoch 3/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 4.4331 - dice_coef: 0.0173 - val_loss: 4.4842 - val_dice_coef: 0.0194\u001b[0m\n",
      "\u001b[34mEpoch 4/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 4.3249 - dice_coef: 0.0195 - val_loss: 4.5053 - val_dice_coef: 0.0225\u001b[0m\n",
      "\u001b[34mEpoch 5/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 4.1401 - dice_coef: 0.0231 - val_loss: 3.3777 - val_dice_coef: 0.0268\u001b[0m\n",
      "\u001b[34mEpoch 6/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 3.9954 - dice_coef: 0.0260 - val_loss: 3.9846 - val_dice_coef: 0.0302\u001b[0m\n",
      "\u001b[34mEpoch 7/150\u001b[0m\n",
      "\u001b[34m - 122s - loss: 3.8817 - dice_coef: 0.0295 - val_loss: 6.4093 - val_dice_coef: 0.0350\u001b[0m\n",
      "\u001b[34mEpoch 8/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 3.7408 - dice_coef: 0.0331 - val_loss: 3.0157 - val_dice_coef: 0.0392\u001b[0m\n",
      "\u001b[34mEpoch 9/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 3.5838 - dice_coef: 0.0376 - val_loss: 4.9929 - val_dice_coef: 0.0460\u001b[0m\n",
      "\u001b[34mEpoch 10/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 3.4343 - dice_coef: 0.0422 - val_loss: 3.1805 - val_dice_coef: 0.0522\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00010: saving model to /opt/ml//model/DUnet/DUnet-10-0.05.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 11/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 3.3534 - dice_coef: 0.0473 - val_loss: 2.7515 - val_dice_coef: 0.0581\u001b[0m\n",
      "\u001b[34mEpoch 12/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 3.2273 - dice_coef: 0.0546 - val_loss: 2.2573 - val_dice_coef: 0.0664\u001b[0m\n",
      "\u001b[34mEpoch 13/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 3.0798 - dice_coef: 0.0589 - val_loss: 2.6457 - val_dice_coef: 0.0731\u001b[0m\n",
      "\u001b[34mEpoch 14/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 2.9666 - dice_coef: 0.0680 - val_loss: 2.0028 - val_dice_coef: 0.0839\u001b[0m\n",
      "\u001b[34mEpoch 15/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 2.8462 - dice_coef: 0.0761 - val_loss: 2.6852 - val_dice_coef: 0.0907\u001b[0m\n",
      "\u001b[34mEpoch 16/150\u001b[0m\n",
      "\u001b[34m - 122s - loss: 2.6791 - dice_coef: 0.0879 - val_loss: 2.3447 - val_dice_coef: 0.0981\u001b[0m\n",
      "\u001b[34mEpoch 17/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 2.6025 - dice_coef: 0.0959 - val_loss: 2.0100 - val_dice_coef: 0.1115\u001b[0m\n",
      "\u001b[34mEpoch 18/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 2.4497 - dice_coef: 0.1097 - val_loss: 3.4960 - val_dice_coef: 0.1186\u001b[0m\n",
      "\u001b[34mEpoch 19/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 2.4073 - dice_coef: 0.1171 - val_loss: 2.6331 - val_dice_coef: 0.1212\u001b[0m\n",
      "\u001b[34mEpoch 20/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 2.1847 - dice_coef: 0.1393 - val_loss: 2.4809 - val_dice_coef: 0.1541\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00020: saving model to /opt/ml//model/DUnet/DUnet-20-0.15.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 21/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 2.1015 - dice_coef: 0.1512 - val_loss: 2.0682 - val_dice_coef: 0.1536\u001b[0m\n",
      "\u001b[34mEpoch 22/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.9459 - dice_coef: 0.1745 - val_loss: 1.6192 - val_dice_coef: 0.1789\u001b[0m\n",
      "\u001b[34mEpoch 23/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.9022 - dice_coef: 0.1879 - val_loss: 2.6676 - val_dice_coef: 0.1792\u001b[0m\n",
      "\u001b[34mEpoch 24/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.7776 - dice_coef: 0.2050 - val_loss: 1.3364 - val_dice_coef: 0.1915\u001b[0m\n",
      "\u001b[34mEpoch 25/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.5836 - dice_coef: 0.2375 - val_loss: 1.2274 - val_dice_coef: 0.2704\u001b[0m\n",
      "\u001b[34mEpoch 26/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.5939 - dice_coef: 0.2491 - val_loss: 1.5750 - val_dice_coef: 0.1837\u001b[0m\n",
      "\u001b[34mEpoch 27/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.4430 - dice_coef: 0.2775 - val_loss: 1.4793 - val_dice_coef: 0.2975\u001b[0m\n",
      "\u001b[34mEpoch 28/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.4071 - dice_coef: 0.2909 - val_loss: 0.6892 - val_dice_coef: 0.2319\u001b[0m\n",
      "\u001b[34mEpoch 29/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.2910 - dice_coef: 0.3218 - val_loss: 2.8757 - val_dice_coef: 0.2910\u001b[0m\n",
      "\u001b[34mEpoch 30/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.2588 - dice_coef: 0.3301 - val_loss: 1.1082 - val_dice_coef: 0.3715\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00030: saving model to /opt/ml//model/DUnet/DUnet-30-0.37.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 31/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.1848 - dice_coef: 0.3553 - val_loss: 2.6715 - val_dice_coef: 0.2532\u001b[0m\n",
      "\u001b[34mEpoch 32/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.0679 - dice_coef: 0.3885 - val_loss: 0.9155 - val_dice_coef: 0.3862\u001b[0m\n",
      "\u001b[34mEpoch 33/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 1.0918 - dice_coef: 0.3897 - val_loss: 0.7560 - val_dice_coef: 0.3974\u001b[0m\n",
      "\u001b[34mEpoch 34/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.0524 - dice_coef: 0.4067 - val_loss: 0.7464 - val_dice_coef: 0.3549\u001b[0m\n",
      "\u001b[34mEpoch 35/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 1.0461 - dice_coef: 0.4075 - val_loss: 0.8786 - val_dice_coef: 0.2529\u001b[0m\n",
      "\u001b[34mEpoch 36/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.9347 - dice_coef: 0.4331 - val_loss: 0.8282 - val_dice_coef: 0.2520\u001b[0m\n",
      "\u001b[34mEpoch 37/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.8987 - dice_coef: 0.4529 - val_loss: 0.3483 - val_dice_coef: 0.4938\u001b[0m\n",
      "\u001b[34mEpoch 38/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.8416 - dice_coef: 0.4764 - val_loss: 3.0927 - val_dice_coef: 0.1103\u001b[0m\n",
      "\u001b[34mEpoch 39/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.9087 - dice_coef: 0.4534 - val_loss: 0.4648 - val_dice_coef: 0.3808\u001b[0m\n",
      "\u001b[34mEpoch 40/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.9180 - dice_coef: 0.4736 - val_loss: 1.3277 - val_dice_coef: 0.4314\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00040: saving model to /opt/ml//model/DUnet/DUnet-40-0.43.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 41/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.8461 - dice_coef: 0.4797 - val_loss: 0.4435 - val_dice_coef: 0.4774\u001b[0m\n",
      "\u001b[34mEpoch 42/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.8321 - dice_coef: 0.4934 - val_loss: 0.3882 - val_dice_coef: 0.4714\u001b[0m\n",
      "\u001b[34mEpoch 43/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.8463 - dice_coef: 0.4901 - val_loss: 0.4290 - val_dice_coef: 0.3648\u001b[0m\n",
      "\u001b[34mEpoch 44/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7759 - dice_coef: 0.5102 - val_loss: 0.7096 - val_dice_coef: 0.4793\u001b[0m\n",
      "\u001b[34mEpoch 45/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7254 - dice_coef: 0.5270 - val_loss: 0.3350 - val_dice_coef: 0.5189\u001b[0m\n",
      "\u001b[34mEpoch 46/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7536 - dice_coef: 0.5226 - val_loss: 1.1709 - val_dice_coef: 0.3526\u001b[0m\n",
      "\u001b[34mEpoch 47/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7535 - dice_coef: 0.5223 - val_loss: 0.3704 - val_dice_coef: 0.4773\u001b[0m\n",
      "\u001b[34mEpoch 48/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7321 - dice_coef: 0.5416 - val_loss: 0.3651 - val_dice_coef: 0.5403\u001b[0m\n",
      "\u001b[34mEpoch 49/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.7298 - dice_coef: 0.5348 - val_loss: 0.6160 - val_dice_coef: 0.5238\u001b[0m\n",
      "\u001b[34mEpoch 50/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7127 - dice_coef: 0.5420 - val_loss: 0.8489 - val_dice_coef: 0.3168\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00050: saving model to /opt/ml//model/DUnet/DUnet-50-0.32.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 51/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6950 - dice_coef: 0.5443 - val_loss: 0.9365 - val_dice_coef: 0.5000\u001b[0m\n",
      "\u001b[34mEpoch 52/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6532 - dice_coef: 0.5582 - val_loss: 0.8513 - val_dice_coef: 0.5303\u001b[0m\n",
      "\u001b[34mEpoch 53/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.6546 - dice_coef: 0.5688 - val_loss: 0.4402 - val_dice_coef: 0.6080\u001b[0m\n",
      "\u001b[34mEpoch 54/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7120 - dice_coef: 0.5496 - val_loss: 0.5208 - val_dice_coef: 0.4010\u001b[0m\n",
      "\u001b[34mEpoch 55/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6219 - dice_coef: 0.5728 - val_loss: 0.3011 - val_dice_coef: 0.5420\u001b[0m\n",
      "\u001b[34mEpoch 56/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6762 - dice_coef: 0.5607 - val_loss: 0.4314 - val_dice_coef: 0.3879\u001b[0m\n",
      "\u001b[34mEpoch 57/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.6907 - dice_coef: 0.5669 - val_loss: 0.4685 - val_dice_coef: 0.5309\u001b[0m\n",
      "\u001b[34mEpoch 58/150\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m - 120s - loss: 0.6668 - dice_coef: 0.5659 - val_loss: 1.0092 - val_dice_coef: 0.4623\u001b[0m\n",
      "\u001b[34mEpoch 59/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.7214 - dice_coef: 0.5609 - val_loss: 0.3077 - val_dice_coef: 0.5677\u001b[0m\n",
      "\u001b[34mEpoch 60/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6103 - dice_coef: 0.5890 - val_loss: 0.7484 - val_dice_coef: 0.3719\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00060: saving model to /opt/ml//model/DUnet/DUnet-60-0.37.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 61/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6258 - dice_coef: 0.5774 - val_loss: 0.5647 - val_dice_coef: 0.4658\u001b[0m\n",
      "\u001b[34mEpoch 62/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.6339 - dice_coef: 0.5898 - val_loss: 3.3210 - val_dice_coef: 0.1509\u001b[0m\n",
      "\u001b[34mEpoch 63/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6418 - dice_coef: 0.5788 - val_loss: 1.2752 - val_dice_coef: 0.2324\u001b[0m\n",
      "\u001b[34mEpoch 64/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.6083 - dice_coef: 0.5929 - val_loss: 1.4551 - val_dice_coef: 0.5147\u001b[0m\n",
      "\u001b[34mEpoch 65/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.6111 - dice_coef: 0.5916 - val_loss: 0.3051 - val_dice_coef: 0.5048\u001b[0m\n",
      "\u001b[34mEpoch 66/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5914 - dice_coef: 0.5984 - val_loss: 0.8333 - val_dice_coef: 0.4252\u001b[0m\n",
      "\u001b[34mEpoch 67/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.5764 - dice_coef: 0.6076 - val_loss: 0.2790 - val_dice_coef: 0.5687\u001b[0m\n",
      "\u001b[34mEpoch 68/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6374 - dice_coef: 0.5873 - val_loss: 0.9527 - val_dice_coef: 0.5008\u001b[0m\n",
      "\u001b[34mEpoch 69/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5508 - dice_coef: 0.6148 - val_loss: 0.9106 - val_dice_coef: 0.5171\u001b[0m\n",
      "\u001b[34mEpoch 70/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5938 - dice_coef: 0.6094 - val_loss: 1.1912 - val_dice_coef: 0.5017\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00070: saving model to /opt/ml//model/DUnet/DUnet-70-0.50.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 71/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5844 - dice_coef: 0.6103 - val_loss: 2.6265 - val_dice_coef: 0.4889\u001b[0m\n",
      "\u001b[34mEpoch 72/150\u001b[0m\n",
      "\u001b[34m - 122s - loss: 0.5552 - dice_coef: 0.6114 - val_loss: 1.0674 - val_dice_coef: 0.5040\u001b[0m\n",
      "\u001b[34mEpoch 73/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5735 - dice_coef: 0.6150 - val_loss: 0.4956 - val_dice_coef: 0.5082\u001b[0m\n",
      "\u001b[34mEpoch 74/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5487 - dice_coef: 0.6172 - val_loss: 1.2906 - val_dice_coef: 0.5158\u001b[0m\n",
      "\u001b[34mEpoch 75/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.6215 - dice_coef: 0.5985 - val_loss: 0.6593 - val_dice_coef: 0.4584\u001b[0m\n",
      "\u001b[34mEpoch 76/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5337 - dice_coef: 0.6333 - val_loss: 0.7974 - val_dice_coef: 0.5445\u001b[0m\n",
      "\u001b[34mEpoch 77/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5419 - dice_coef: 0.6249 - val_loss: 0.3911 - val_dice_coef: 0.5806\u001b[0m\n",
      "\u001b[34mEpoch 78/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5394 - dice_coef: 0.6158 - val_loss: 0.3044 - val_dice_coef: 0.5772\u001b[0m\n",
      "\u001b[34mEpoch 79/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5474 - dice_coef: 0.6210 - val_loss: 0.7902 - val_dice_coef: 0.5695\u001b[0m\n",
      "\u001b[34mEpoch 80/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5556 - dice_coef: 0.6234 - val_loss: 2.9544 - val_dice_coef: 0.4090\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00080: saving model to /opt/ml//model/DUnet/DUnet-80-0.41.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 81/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.5436 - dice_coef: 0.6207 - val_loss: 0.5289 - val_dice_coef: 0.4406\u001b[0m\n",
      "\u001b[34mEpoch 82/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5493 - dice_coef: 0.6312 - val_loss: 0.4347 - val_dice_coef: 0.4754\u001b[0m\n",
      "\u001b[34mEpoch 83/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5716 - dice_coef: 0.6202 - val_loss: 0.4079 - val_dice_coef: 0.5531\u001b[0m\n",
      "\u001b[34mEpoch 84/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5968 - dice_coef: 0.6156 - val_loss: 1.0413 - val_dice_coef: 0.4867\u001b[0m\n",
      "\u001b[34mEpoch 85/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5000 - dice_coef: 0.6406 - val_loss: 0.5676 - val_dice_coef: 0.5718\u001b[0m\n",
      "\u001b[34mEpoch 86/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.5435 - dice_coef: 0.6276 - val_loss: 0.5153 - val_dice_coef: 0.6051\u001b[0m\n",
      "\u001b[34mEpoch 87/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5658 - dice_coef: 0.6257 - val_loss: 0.3437 - val_dice_coef: 0.4886\u001b[0m\n",
      "\u001b[34mEpoch 88/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5871 - dice_coef: 0.6249 - val_loss: 0.3394 - val_dice_coef: 0.6341\u001b[0m\n",
      "\u001b[34mEpoch 89/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5108 - dice_coef: 0.6398 - val_loss: 0.5085 - val_dice_coef: 0.5200\u001b[0m\n",
      "\u001b[34mEpoch 90/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5472 - dice_coef: 0.6313 - val_loss: 3.1507 - val_dice_coef: 0.4376\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 00090: saving model to /opt/ml//model/DUnet/DUnet-90-0.44.hdf5\u001b[0m\n",
      "\u001b[34mEpoch 91/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5104 - dice_coef: 0.6359 - val_loss: 0.3578 - val_dice_coef: 0.5191\u001b[0m\n",
      "\u001b[34mEpoch 92/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.5081 - dice_coef: 0.6430 - val_loss: 0.4690 - val_dice_coef: 0.6832\u001b[0m\n",
      "\u001b[34mEpoch 93/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.5341 - dice_coef: 0.6364 - val_loss: 0.3899 - val_dice_coef: 0.5060\u001b[0m\n",
      "\u001b[34mEpoch 94/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.5052 - dice_coef: 0.6523 - val_loss: 0.4053 - val_dice_coef: 0.6006\u001b[0m\n",
      "\u001b[34mEpoch 95/150\u001b[0m\n",
      "\u001b[34m - 120s - loss: 0.4834 - dice_coef: 0.6524 - val_loss: 1.2880 - val_dice_coef: 0.5107\u001b[0m\n",
      "\u001b[34mEpoch 96/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.4951 - dice_coef: 0.6488 - val_loss: 0.5109 - val_dice_coef: 0.6578\u001b[0m\n",
      "\u001b[34mEpoch 97/150\u001b[0m\n",
      "\u001b[34m - 121s - loss: 0.5550 - dice_coef: 0.6384 - val_loss: 0.6588 - val_dice_coef: 0.5368\u001b[0m\n",
      "\u001b[34mEpoch 98/150\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs={\"atlas\":atlas_input}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "“alphapose.ipynb”",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
